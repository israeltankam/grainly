{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b324b21f-1d3c-4999-a2cc-f89a5e04e7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  lai\n",
      "0 2024-04-18  0.0\n",
      "1 2024-04-19  0.1\n",
      "2 2024-04-20  0.1\n",
      "3 2024-04-21  0.1\n",
      "4 2024-04-22  0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "model.py\n",
    "\n",
    "Simulates basic STICS model outputs for a maize field based on user inputs.\n",
    "\n",
    "Inputs:\n",
    "    soil: dict containing soil properties\n",
    "        - texture: str (e.g., 'Loamy')\n",
    "        - depth: float (m)\n",
    "        - field_capacity: float (m3/m3)\n",
    "        - wilting_point: float (m3/m3)\n",
    "        - initial_water: float (mm)\n",
    "        - initial_nitrate: float (kg/ha)\n",
    "\n",
    "    weather: pd.DataFrame with daily columns:\n",
    "        - date: datetime\n",
    "        - tmin: float (°C)\n",
    "        - tmax: float (°C)\n",
    "        - precipitation: float (mm)\n",
    "        - radiation: float (MJ/m2)\n",
    "\n",
    "    crop: dict with crop management settings\n",
    "        - variety: str\n",
    "        - sowing_date: datetime\n",
    "        - density: float (plants/m2)\n",
    "        - sowing_depth: float (cm)\n",
    "        - fertilizer_schedule: list of tuples (date, amount_kgN/ha)\n",
    "        - irrigation_schedule: list of tuples (date, amount_mm)\n",
    "\n",
    "    parameters: dict of model parameters\n",
    "        - light_use_efficiency: float (gDM/MJ)\n",
    "        - max_leaf_area_index: float\n",
    "        - root_depth_rate: float (cm/day)\n",
    "        - n_uptake_efficiency: float (kgN/kgDM)\n",
    "\n",
    "Outputs:\n",
    "    results: dict of pd.DataFrame with time series:\n",
    "        - lai: Leaf Area Index\n",
    "        - biomass: Total aboveground biomass (g/m2)\n",
    "        - yield: Grain yield (g/m2)\n",
    "        - soil_water: Available soil water (mm)\n",
    "        - soil_nitrate: Soil nitrate content (kg/ha)\n",
    "        - water_balance: Precipitation, evapotranspiration, drainage\n",
    "        - n_balance: N inputs, uptake, losses\n",
    "\n",
    "Example usage:\n",
    "    from model import run_simulation\n",
    "    results = run_simulation(soil, weather, crop, parameters)\n",
    "    print(results['lai'].head())\n",
    "\"\"\"\n",
    "\n",
    "def run_simulation(soil, weather, crop, parameters):\n",
    "    # Prepare time axis\n",
    "    df = weather.copy().reset_index(drop=True)\n",
    "    n = len(df)\n",
    "\n",
    "    # Initialize output arrays\n",
    "    lai = np.zeros(n)\n",
    "    biomass = np.zeros(n)\n",
    "    soil_water = np.zeros(n)\n",
    "    soil_nitrate = np.zeros(n)\n",
    "    water_upt = np.zeros(n)\n",
    "    drainage = np.zeros(n)\n",
    "    n_uptake = np.zeros(n)\n",
    "\n",
    "    # Initial states\n",
    "    soil_water[0] = soil['initial_water']\n",
    "    soil_nitrate[0] = soil['initial_nitrate']\n",
    "\n",
    "    # Phenological tracking (simple degree-day)\n",
    "    base_temp = 8.0  # °C\n",
    "    cum_dd = 0.0\n",
    "    dd_emergence = 100\n",
    "    dd_maturity = 1200\n",
    "\n",
    "    for i in range(1, n):\n",
    "        # Degree-days\n",
    "        tavg = (df.loc[i, 'tmax'] + df.loc[i, 'tmin']) / 2\n",
    "        dd = max(0, tavg - base_temp)\n",
    "        cum_dd += dd\n",
    "\n",
    "        # LAI development\n",
    "        if cum_dd < dd_emergence:\n",
    "            lai[i] = 0.1\n",
    "        elif cum_dd < dd_maturity:\n",
    "            lai[i] = min(parameters['max_leaf_area_index'],\n",
    "                        parameters['max_leaf_area_index'] * ((cum_dd - dd_emergence) / (dd_maturity - dd_emergence)))\n",
    "        else:\n",
    "            lai[i] = max(0, parameters['max_leaf_area_index'] * (1 - (cum_dd - dd_maturity) / (dd_maturity * 0.2)))\n",
    "\n",
    "        # Radiation interception and biomass\n",
    "        rad = df.loc[i, 'radiation']\n",
    "        intercepted = rad * (1 - np.exp(-0.5 * lai[i]))\n",
    "        dm_gain = intercepted * parameters['light_use_efficiency']\n",
    "        biomass[i] = biomass[i-1] + dm_gain\n",
    "\n",
    "        # Soil water balance\n",
    "        precip = df.loc[i, 'precipitation']\n",
    "        et0 = 0.5 * rad  # reference ET (simplified)\n",
    "        et_crop = et0 * (lai[i] / parameters['max_leaf_area_index'])\n",
    "        inflow = precip + sum(amount for date, amount in crop.get('irrigation_schedule', []) if date == df.loc[i, 'date'])\n",
    "        outflow = et_crop\n",
    "        soil_water[i] = max(0, soil_water[i-1] + inflow - outflow)\n",
    "        drainage[i] = max(0, (soil_water[i] - soil['field_capacity']) if soil_water[i] > soil['field_capacity'] else 0)\n",
    "\n",
    "        # Nitrogen uptake and balance\n",
    "        # Fertilizer application\n",
    "        fert = sum(amount for date, amount in crop.get('fertilizer_schedule', []) if date == df.loc[i, 'date'])\n",
    "        soil_nitrate[i] = soil_nitrate[i-1] + fert\n",
    "        # Uptake\n",
    "        n_uptake[i] = dm_gain * parameters['n_uptake_efficiency']\n",
    "        soil_nitrate[i] = max(0, soil_nitrate[i] - n_uptake[i])\n",
    "\n",
    "    # Package results\n",
    "    results = {\n",
    "        'lai': pd.DataFrame({'date': df['date'], 'lai': lai}),\n",
    "        'biomass': pd.DataFrame({'date': df['date'], 'biomass': biomass}),\n",
    "        'yield': pd.DataFrame({'date': df['date'], 'yield': biomass * 0.45}),  # partition to grain\n",
    "        'soil_water': pd.DataFrame({'date': df['date'], 'soil_water': soil_water}),\n",
    "        'soil_nitrate': pd.DataFrame({'date': df['date'], 'soil_nitrate': soil_nitrate}),\n",
    "        'water_balance': pd.DataFrame({'date': df['date'], 'precip': df['precipitation'],\n",
    "                                       'et': et_crop, 'drainage': drainage}),\n",
    "        'n_balance': pd.DataFrame({'date': df['date'], 'n_uptake': n_uptake, 'fert': [sum(amount for d, amount in crop.get('fertilizer_schedule', []) if d == date) for date in df['date']]})\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Example usage with dummy inputs\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # Generate dummy weather for one season\n",
    "    start = datetime(2024, 4, 18)\n",
    "    dates = [start + timedelta(days=i) for i in range(150)]\n",
    "    weather = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'tmin': np.random.uniform(10, 15, size=150),\n",
    "        'tmax': np.random.uniform(20, 30, size=150),\n",
    "        'precipitation': np.random.uniform(0, 10, size=150),\n",
    "        'radiation': np.random.uniform(10, 25, size=150),\n",
    "    })\n",
    "\n",
    "    soil = {\n",
    "        'texture': 'Loamy',\n",
    "        'depth': 1.2,\n",
    "        'field_capacity': 0.30,\n",
    "        'wilting_point': 0.12,\n",
    "        'initial_water': 150,\n",
    "        'initial_nitrate': 50,\n",
    "    }\n",
    "\n",
    "    crop = {\n",
    "        'variety': 'Maize Hybrid A',\n",
    "        'sowing_date': start,\n",
    "        'density': 9,\n",
    "        'sowing_depth': 5,\n",
    "        'fertilizer_schedule': [(start + timedelta(days=30), 100)],\n",
    "        'irrigation_schedule': [(start + timedelta(days=45), 20)],\n",
    "    }\n",
    "\n",
    "    parameters = {\n",
    "        'light_use_efficiency': 1.5,\n",
    "        'max_leaf_area_index': 5.0,\n",
    "        'root_depth_rate': 0.8,\n",
    "        'n_uptake_efficiency': 0.03,\n",
    "    }\n",
    "\n",
    "    results = run_simulation(soil, weather, crop, parameters)\n",
    "    print(results['lai'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437a69be-8839-4920-bd78-ced1ad9de6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:28:44,871 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-05 19:28:44,872 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://cds.climate.copernicus.eu/api/retrieve/v1/processes/reanalysis-era5-land/execution\ncost limits exceeded\nYour request is too large, please reduce your selection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 109\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 109\u001b[0m     __main__()\n",
      "Cell \u001b[1;32mIn[5], line 105\u001b[0m, in \u001b[0;36m__main__\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2025-04-20\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    104\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2025-09-15\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 105\u001b[0m df \u001b[38;5;241m=\u001b[39m fetch_weather(lat, lon, start, end)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m, in \u001b[0;36mfetch_weather\u001b[1;34m(lat, lon, start_date, end_date, output_path)\u001b[0m\n\u001b[0;32m     49\u001b[0m     end \u001b[38;5;241m=\u001b[39m end_date\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Request ERA5-Land daily aggregated data\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m c\u001b[38;5;241m.\u001b[39mretrieve(\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreanalysis-era5-land\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     54\u001b[0m     {\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(_VARIABLES\u001b[38;5;241m.\u001b[39mkeys()),\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mdate_range(start, end, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)],\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m7\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mdate_range(start, end, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)],\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m: [d[\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m10\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mdate_range(start, end, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)],\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m00:00\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# daily aggregated fields\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetcdf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea\u001b[39m\u001b[38;5;124m'\u001b[39m: [lat \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0005\u001b[39m, lon \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.0005\u001b[39m, lat \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.0005\u001b[39m, lon \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0005\u001b[39m],  \u001b[38;5;66;03m# small box around point\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     },\n\u001b[0;32m     63\u001b[0m     output_path\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Load and extract point time series\u001b[39;00m\n\u001b[0;32m     67\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(output_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datapi\\legacy_api_client.py:169\u001b[0m, in \u001b[0;36mLegacyApiClient.retrieve\u001b[1;34m(self, name, request, target)\u001b[0m\n\u001b[0;32m    167\u001b[0m submitted: Remote \u001b[38;5;241m|\u001b[39m Results\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_until_complete:\n\u001b[1;32m--> 169\u001b[0m     submitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msubmit_and_wait_on_results(\n\u001b[0;32m    170\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    171\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     submitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    175\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    176\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m    177\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datapi\\api_client.py:399\u001b[0m, in \u001b[0;36mApiClient.submit_and_wait_on_results\u001b[1;34m(self, collection_id, request)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit_and_wait_on_results\u001b[39m(\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m, collection_id: \u001b[38;5;28mstr\u001b[39m, request: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]\n\u001b[0;32m    385\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m datapi\u001b[38;5;241m.\u001b[39mResults:\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Submit a request and wait for the results to be ready.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    datapi.Results\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve_api\u001b[38;5;241m.\u001b[39msubmit(collection_id, request)\u001b[38;5;241m.\u001b[39mget_results()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datapi\\processing.py:794\u001b[0m, in \u001b[0;36mProcessing.submit\u001b[1;34m(self, collection_id, request)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, collection_id: \u001b[38;5;28mstr\u001b[39m, request: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Remote:\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_process(collection_id)\u001b[38;5;241m.\u001b[39msubmit(request)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datapi\\processing.py:317\u001b[0m, in \u001b[0;36mProcess.submit\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, request: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m datapi\u001b[38;5;241m.\u001b[39mRemote:\n\u001b[0;32m    306\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Submit a request.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m    datapi.Remote\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m     job \u001b[38;5;241m=\u001b[39m Job\u001b[38;5;241m.\u001b[39mfrom_request(\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/execution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    320\u001b[0m         json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: request},\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_kwargs,\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m job\u001b[38;5;241m.\u001b[39mget_remote()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datapi\\processing.py:177\u001b[0m, in \u001b[0;36mApiResponse.from_request\u001b[1;34m(cls, method, url, headers, session, retry_options, request_options, download_options, sleep_max, cleanup, log_callback, log_messages, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m response \u001b[38;5;241m=\u001b[39m robust_request(\n\u001b[0;32m    173\u001b[0m     method, url, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m log(logging\u001b[38;5;241m.\u001b[39mDEBUG, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREPLY \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, callback\u001b[38;5;241m=\u001b[39mlog_callback)\n\u001b[1;32m--> 177\u001b[0m cads_raise_for_status(response)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    180\u001b[0m     response,\n\u001b[0;32m    181\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m     log_callback\u001b[38;5;241m=\u001b[39mlog_callback,\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_messages:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datapi\\processing.py:100\u001b[0m, in \u001b[0;36mcads_raise_for_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m         message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     95\u001b[0m             [\n\u001b[0;32m     96\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     97\u001b[0m                 error_json_to_message(error_json),\n\u001b[0;32m     98\u001b[0m             ]\n\u001b[0;32m     99\u001b[0m         )\n\u001b[1;32m--> 100\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[0;32m    101\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://cds.climate.copernicus.eu/api/retrieve/v1/processes/reanalysis-era5-land/execution\ncost limits exceeded\nYour request is too large, please reduce your selection."
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Mapping from ERA5-Land variables to our names\n",
    "_VARIABLES = {\n",
    "    '2m_temperature': 't2m',\n",
    "    'total_precipitation': 'tp',\n",
    "    'surface_net_solar_radiation': 'ssr'\n",
    "}\n",
    "\n",
    "# ERA5-Land expects dates in YYYY-MM-DD\n",
    "\n",
    "def fetch_weather(lat, lon, start_date, end_date, output_path='/tmp/era5_land.nc'):\n",
    "    \"\"\"\n",
    "    Downloads and processes daily weather data from Copernicus ERA5-Land for a point.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lat, lon : float\n",
    "        Geographic coordinates of the point (decimal degrees).\n",
    "    start_date, end_date : str or datetime\n",
    "        Start and end dates in 'YYYY-MM-DD' or datetime.\n",
    "    output_path : str\n",
    "        Path to save the downloaded NetCDF file.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame with columns:\n",
    "      - date: datetime\n",
    "      - tmin: °C\n",
    "      - tmax: °C\n",
    "      - precipitation: mm/day\n",
    "      - radiation: MJ/m2/day\n",
    "    \"\"\"\n",
    "    # Format dates\n",
    "    if isinstance(start_date, datetime):\n",
    "        start = start_date.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        start = start_date\n",
    "    if isinstance(end_date, datetime):\n",
    "        end = end_date.strftime('%Y-%m-%d')\n",
    "    else:\n",
    "        end = end_date\n",
    "\n",
    "    # Request ERA5-Land daily aggregated data\n",
    "    c.retrieve(\n",
    "        'reanalysis-era5-land',\n",
    "        {\n",
    "            'variable': list(_VARIABLES.keys()),\n",
    "            'year': [d[:4] for d in pd.date_range(start, end, freq='D').strftime('%Y')],\n",
    "            'month': [d[5:7] for d in pd.date_range(start, end, freq='D').strftime('%m')],\n",
    "            'day': [d[8:10] for d in pd.date_range(start, end, freq='D').strftime('%d')],\n",
    "            'time': ['00:00'],  # daily aggregated fields\n",
    "            'format': 'netcdf',\n",
    "            'area': [lat + 0.0005, lon - 0.0005, lat - 0.0005, lon + 0.0005],  # small box around point\n",
    "        },\n",
    "        output_path\n",
    "    )\n",
    "\n",
    "    # Load and extract point time series\n",
    "    ds = xr.open_dataset(output_path)\n",
    "\n",
    "    # Select nearest grid point\n",
    "    ds_point = ds.sel(\n",
    "        latitude=lat, longitude=lon, method='nearest'\n",
    "    )\n",
    "\n",
    "    # Convert units and aggregate\n",
    "    df = ds_point.to_dataframe()\n",
    "    df = df.reset_index()\n",
    "    df['date'] = pd.to_datetime(df['time']).dt.date\n",
    "\n",
    "    # Daily min/max temperature (K to °C)\n",
    "    # ERA5-Land 't2m' is hourly; but here we requested daily, so treat as daily mean\n",
    "    df_daily = df.groupby('date').agg({\n",
    "        't2m': ['min', 'max', 'mean'],\n",
    "        'tp': 'last',\n",
    "        'ssr': 'last'\n",
    "    })\n",
    "    df_daily.columns = ['tmin_k', 'tmax_k', 'tmean_k', 'precipitation_m', 'radiation_j']\n",
    "\n",
    "    # Convert to desired units\n",
    "    df_daily['tmin'] = df_daily['tmin_k'] - 273.15\n",
    "    df_daily['tmax'] = df_daily['tmax_k'] - 273.15\n",
    "    # precipitation in m to mm\n",
    "    df_daily['precipitation'] = df_daily['precipitation_m'] * 1000\n",
    "    # radiation in J/m2 to MJ/m2\n",
    "    df_daily['radiation'] = df_daily['radiation_j'] / 1e6\n",
    "\n",
    "    # Final DataFrame\n",
    "    weather = df_daily[['tmin', 'tmax', 'precipitation', 'radiation']].reset_index()\n",
    "    return weather\n",
    "\n",
    "# Example usage\n",
    "def __main__():\n",
    "    lat, lon = 45.78, 3.08  # Clermont-Ferrand\n",
    "    start = '2025-04-20'\n",
    "    end = '2025-09-15'\n",
    "    df = fetch_weather(lat, lon, start, end)\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    __main__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea490aa6-f607-4f53-870f-3fd60a67affd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic forecast test passed          date  tmin  tmax  precipitation  radiation\n",
      "0  2025-05-06   0.0  10.0            1.0        5.0\n",
      "1  2025-05-07   1.0  11.0            1.0        5.0\n",
      "2  2025-05-08   2.0  12.0            1.0        5.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "\n",
    "def fetch_historical(lat, lon, start_date, end_date, timezone=\"Europe/Paris\"):\n",
    "    \"\"\"\n",
    "    Fetch past weather data using the Open-Meteo Archive API.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        f\"?latitude={lat}&longitude={lon}\"\n",
    "        f\"&start_date={start_date}&end_date={end_date}\"\n",
    "        \"&daily=temperature_2m_min,temperature_2m_max,precipitation_sum,shortwave_radiation_sum\"\n",
    "        f\"&timezone={timezone}\"\n",
    "    )\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    data = r.json().get(\"daily\", {})\n",
    "\n",
    "    radiation_raw = data.get(\"shortwave_radiation_sum\", [])\n",
    "    radiation = [(x * 0.0036) if x is not None else np.nan for x in radiation_raw]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": pd.to_datetime(data.get(\"time\", [])),\n",
    "        \"tmin\": data.get(\"temperature_2m_min\", []),\n",
    "        \"tmax\": data.get(\"temperature_2m_max\", []),\n",
    "        \"precipitation\": data.get(\"precipitation_sum\", []),\n",
    "        \"radiation\": radiation,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_moving_avg_forecast(lat, lon, start_date, end_date, years=4):\n",
    "    \"\"\"\n",
    "    Estimate future weather by averaging historical data for the same calendar days\n",
    "    over the previous `years` years.\n",
    "\n",
    "    Returns a DataFrame covering [start_date..end_date], with columns: date, tmin, tmax,\n",
    "    precipitation, radiation.\n",
    "    \"\"\"\n",
    "    sd = pd.to_datetime(start_date).date()\n",
    "    ed = pd.to_datetime(end_date).date()\n",
    "    frames = []\n",
    "\n",
    "    # Collect historical series for each of the previous `years` years\n",
    "    for y in range(1, years+1):\n",
    "        year_offset_sd = sd.replace(year=sd.year - y)\n",
    "        year_offset_ed = ed.replace(year=ed.year - y)\n",
    "        df_hist = fetch_historical(lat, lon,\n",
    "                                   year_offset_sd.isoformat(),\n",
    "                                   year_offset_ed.isoformat())\n",
    "        # Align dates to forecast year\n",
    "        df_hist['day_of_year'] = df_hist['date'].dt.strftime('%m-%d')\n",
    "        frames.append(df_hist)\n",
    "\n",
    "    # Concatenate and compute mean for each calendar day\n",
    "    df_concat = pd.concat(frames, ignore_index=True)\n",
    "    df_avg = df_concat.groupby('day_of_year').agg({\n",
    "        'tmin': 'mean',\n",
    "        'tmax': 'mean',\n",
    "        'precipitation': 'mean',\n",
    "        'radiation': 'mean'\n",
    "    }).reset_index()\n",
    "    # Reconstruct forecast dates\n",
    "    forecast_days = (ed - sd).days + 1\n",
    "    dates = [sd + timedelta(days=i) for i in range(forecast_days)]\n",
    "    doy = [d.strftime('%m-%d') for d in dates]\n",
    "    df_forecast = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'day_of_year': doy\n",
    "    }).merge(df_avg, on='day_of_year', how='left')\n",
    "    return df_forecast[['date', 'tmin', 'tmax', 'precipitation', 'radiation']]\n",
    "\n",
    "\n",
    "def fetch_weather(lat, lon, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Unified function: fetch historical up to today-1, then estimate future via moving average.\n",
    "\n",
    "    Returns a DataFrame with columns: date, tmin, tmax, precipitation, radiation.\n",
    "    \"\"\"\n",
    "    sd = pd.to_datetime(start_date).date()\n",
    "    ed = pd.to_datetime(end_date).date()\n",
    "    today = date.today()\n",
    "    yesterday = today - timedelta(days=1)\n",
    "\n",
    "    parts = []\n",
    "    # Historical part\n",
    "    if sd <= yesterday:\n",
    "        hist_end = min(ed, yesterday)\n",
    "        parts.append(fetch_historical(lat, lon, sd.isoformat(), hist_end.isoformat()))\n",
    "\n",
    "    # Future estimate part\n",
    "    if ed >= today:\n",
    "        future_start = max(sd, today)\n",
    "        parts.append(fetch_moving_avg_forecast(lat, lon,\n",
    "                                               future_start.isoformat(),\n",
    "                                               ed.isoformat()))\n",
    "\n",
    "    if not parts:\n",
    "        raise ValueError(\"Requested range yields no data (all dates are in the future?).\")\n",
    "\n",
    "    df = pd.concat(parts).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Tests\n",
    "def _test_synthetic():\n",
    "    # Synthetic historical stub for deterministic test\n",
    "    def stub_hist(lat, lon, start, end):\n",
    "        dates = pd.date_range(start, end)\n",
    "        return pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'tmin': np.arange(len(dates)),\n",
    "            'tmax': np.arange(len(dates)) + 10,\n",
    "            'precipitation': np.ones(len(dates)),\n",
    "            'radiation': np.ones(len(dates)) * 5\n",
    "        })\n",
    "\n",
    "    global fetch_historical\n",
    "    real_hist = fetch_historical\n",
    "    fetch_historical = stub_hist\n",
    "\n",
    "    # Test forecast for 3-day window, averaging stub years\n",
    "    today = date.today()\n",
    "    sd = (today + timedelta(days=1)).isoformat()\n",
    "    ed = (today + timedelta(days=3)).isoformat()\n",
    "    df = fetch_weather(0, 0, sd, ed)\n",
    "    assert len(df) == 3 + 0  # no historical\n",
    "    # tmin average of 0..2 across 4 years => same pattern\n",
    "    print(\"Synthetic forecast test passed\", df)\n",
    "\n",
    "    fetch_historical = real_hist\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _test_synthetic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003101a9-d07f-4ed1-885c-133174481ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
